{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building pipelinines for ML\n",
    "\n",
    "Proceso para realizar un Pipeline donde se hagan transformaciones y por ultimo se implemente un clasificador/regresor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for reproducibility\n",
    "from random import seed as seed1\n",
    "from numpy.random import seed as seed2\n",
    "random_seed = 123\n",
    "seed1(random_seed)\n",
    "seed2(random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_datasets():\n",
    "    from seaborn import get_dataset_names, load_dataset\n",
    "    for name in get_dataset_names():\n",
    "        df = load_dataset(name=name)\n",
    "        print(name, \"*\"*50)\n",
    "        print(df.info())\n",
    "        print(\"\\n\\n\")\n",
    "    return\n",
    "\n",
    "# list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name:str):\n",
    "    from seaborn import load_dataset\n",
    "    df = load_dataset(name=name)\n",
    "    print(f\"{df.shape}\")\n",
    "    print(df.describe().T.to_string())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n",
      "          count       mean        std   min      25%      50%   75%       max\n",
      "survived  891.0   0.383838   0.486592  0.00   0.0000   0.0000   1.0    1.0000\n",
      "pclass    891.0   2.308642   0.836071  1.00   2.0000   3.0000   3.0    3.0000\n",
      "age       714.0  29.699118  14.526497  0.42  20.1250  28.0000  38.0   80.0000\n",
      "sibsp     891.0   0.523008   1.102743  0.00   0.0000   0.0000   1.0    8.0000\n",
      "parch     891.0   0.381594   0.806057  0.00   0.0000   0.0000   0.0    6.0000\n",
      "fare      891.0  32.204208  49.693429  0.00   7.9104  14.4542  31.0  512.3292\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset(name='titanic')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiendo variables de target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target columns:\n",
      "\tsurvived, alive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived  alive\n",
       "0         no       549\n",
       "1         yes      342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target, targetLabel = \"survived\", \"alive\"\n",
    "print(f\"target columns:\\n\\t{', '.join([target, targetLabel])}\")\n",
    "df.groupby([target, targetLabel], dropna=False).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiendo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical columns: 6\n",
      "\tsex, embarked, class, who, deck, embark_town\n",
      "numeric columns: 7\n",
      "\tpclass, age, sibsp, parch, fare, adult_male, alone\n",
      "\n",
      "features=['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alone']\n"
     ]
    }
   ],
   "source": [
    "_cols_cat = list(df.drop([target, targetLabel],axis=1).select_dtypes([\"object\",\"category\",\"string\"]).columns)\n",
    "_cols_num = [c for c in df if c not in [target, targetLabel]+_cols_cat]\n",
    "print(f\"categorical columns: {len(_cols_cat)}\\n\\t{', '.join(_cols_cat)}\")\n",
    "print(f\"numeric columns: {len(_cols_num)}\\n\\t{', '.join(_cols_num)}\")\n",
    "features = [c for c in df if c in _cols_cat+_cols_num]\n",
    "print(f\"\\n{features=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tx_train.shape=(712, 13)\ty_train.shape=(712,)\n",
      "Test:\tx_test.shape=(179, 13)\ty_test.shape=(179,)\n"
     ]
    }
   ],
   "source": [
    "X, y = df[features], df[target]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f\"Train:\\t{x_train.shape=}\\t{y_train.shape=}\\nTest:\\t{x_test.shape=}\\t{y_test.shape=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "## classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_num = Pipeline(steps=[\n",
    "                        (\"impute_mean\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "                        (\"scale_minmax\", MinMaxScaler([0,1]))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "process_cat = Pipeline(steps=[\n",
    "                        (\"impute_constant\", SimpleImputer(fill_value=\"missing\", strategy=\"constant\")),\n",
    "                        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                    [\n",
    "                        (\"categorical\", process_cat, _cols_cat)\n",
    "                        , (\"numerical\", process_num, _cols_num)\n",
    "                    ]\n",
    "            )\n",
    "\n",
    "# pipe = Pipeline(\n",
    "#     [\n",
    "#         (\"preprocessor\", preprocessor)\n",
    "#         , (\"clf\", LogisticRegression())\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_ = {\"LR\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"RF\": RandomForestClassifier()}\n",
    "pipes = dict()\n",
    "for name,clf in clfs_.items():\n",
    "    pipes[name] = Pipeline(\n",
    "                        [\n",
    "                            (\"preprocessor\", preprocessor)\n",
    "                            , (\"clf\", clf)\n",
    "                        ]\n",
    "                    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit with x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(y_true, y_pred):\n",
    "    from sklearn.metrics import classification_report, mean_squared_error, r2_score, accuracy_score, roc_auc_score\n",
    "    metrics = dict()\n",
    "    for op in [\"classification_report\", \"mean_squared_error\", \"r2_score\", \"accuracy_score\", \"roc_auc_score\"]:\n",
    "        if op==\"classification_report\":\n",
    "            print(op,\":\\n\", eval(f\"{op}(y_true, y_pred)\"))\n",
    "            print(\"*\"*50)\n",
    "        else:\n",
    "            metrics[op] = eval(f\"{op}(y_true, y_pred)\")\n",
    "            print(f\"{op}: {metrics[op]}\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR **************************************************\n",
      "classification_report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       114\n",
      "           1       0.79      0.80      0.79        65\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.84      0.84      0.84       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n",
      "**************************************************\n",
      "mean_squared_error: 0.15083798882681565\n",
      "r2_score: 0.3477732793522268\n",
      "accuracy_score: 0.8491620111731844\n",
      "roc_auc_score: 0.8385964912280703\n",
      "\n",
      "\n",
      "KNN **************************************************\n",
      "classification_report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       114\n",
      "           1       0.73      0.74      0.73        65\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.79      0.79      0.79       179\n",
      "weighted avg       0.81      0.80      0.80       179\n",
      "\n",
      "**************************************************\n",
      "mean_squared_error: 0.19553072625698323\n",
      "r2_score: 0.15452091767881249\n",
      "accuracy_score: 0.8044692737430168\n",
      "roc_auc_score: 0.7902834008097165\n",
      "\n",
      "\n",
      "RF **************************************************\n",
      "classification_report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       114\n",
      "           1       0.73      0.78      0.76        65\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.80      0.81      0.80       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "**************************************************\n",
      "mean_squared_error: 0.18435754189944134\n",
      "r2_score: 0.202834008097166\n",
      "accuracy_score: 0.8156424581005587\n",
      "roc_auc_score: 0.808974358974359\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grid_search.fit(x_train, y_train)\n",
    "for name,pipe in pipes.items():\n",
    "    print(f\"{name}\", \"*\"*50)\n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    metrics = get_report(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
